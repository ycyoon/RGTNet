Starting vLLM servers for Llama-3.2-3B benchmark...
Cleaning up existing processes...
Starting Llama-3.2-3B target model on port 8000...
/home/ycyoon/anaconda3/envs/rgtnet/bin/python: Error while finding module specification for 'vllm.entrypoints.openai.api_server' (ModuleNotFoundError: No module named 'vllm')
Starting HarmBench evaluation model on port 8001...
/home/ycyoon/anaconda3/envs/rgtnet/bin/python: Error while finding module specification for 'vllm.entrypoints.openai.api_server' (ModuleNotFoundError: No module named 'vllm')
Starting WildGuard refusal evaluation model on port 8002...
All servers starting... Waiting 60 seconds for initialization...
/home/ycyoon/anaconda3/envs/rgtnet/bin/python: Error while finding module specification for 'vllm.entrypoints.openai.api_server' (ModuleNotFoundError: No module named 'vllm')
Testing server connections...
Target model server not ready
Eval model server not ready
Refusal eval model server not ready
Servers should be ready for benchmark!

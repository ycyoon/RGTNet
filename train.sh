#!/bin/bash

# RGTNet DDP í•™ìŠµ ë° ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

echo "ğŸš€ Starting RGTNet DDP training with benchmark evaluation..."

# GPU ë©”ëª¨ë¦¬ ì²´í¬
echo "ğŸ“Š Checking GPU memory..."
nvidia-smi

# ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p models results

# 7ê°œì˜ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ DDPë¡œ main.py ì‹¤í–‰ (GPU 0ì€ vLLM ì„œë²„ìš©ìœ¼ë¡œ ì œì™¸)
# batch_size 1, gradient_accumulation_steps 8 -> ì‹¤ì§ˆì ì¸ ë°°ì¹˜ í¬ê¸° 1*7*8=56
# --use_amp : ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ Automatic Mixed Precision ì‚¬ìš©
echo "ğŸ”¥ Starting training with 8 GPUs..."
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 torchrun --nproc_per_node=7 --master_port=29600 main.py \
    --pretrained_model_name "meta-llama/Llama-3.2-3B-Instruct" \
    --epochs 3 \
    --batch_size 1 \
    --gradient_accumulation_steps 8 \
    --use_amp \
    --lr 5e-5 \
    --save_path "models/llama3.2_3b_rgtnet.pth" \
    --results_file "results/llama3.2_3b_rgtnet_results.json" \
    --enable_benchmark \
    --benchmark_freq 1 \
    --dropout 0.1 \
    --bias_delta 1.0 \
    --weight_decay 0.01 \
    --warmup_ratio 0.1 \
    --download_datasets \
    --max_seq_len 2048 \
#    --resume_from_checkpoint "models/llama3.2_3b_rgtnet.pth" \
#    --max_iters 100 \
#    --benchmark_dir "StructTransformBench/benchmark" \

echo "âœ… DDP Training completed!"

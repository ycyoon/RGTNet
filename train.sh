#!/bin/bash

# RGTNet DDP í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ìžë™ ìƒ¤ë”© ë° ë³‘í•© í¬í•¨)

echo "ðŸš€ Starting RGTNet DDP training with automatic sharding and merging..."

# ì‹œìž‘ ì‹œê°„ ê¸°ë¡
START_TIME=$(date)
echo "ðŸ“… Training started at: $START_TIME"

# GPU ë©”ëª¨ë¦¬ ì²´í¬
echo "ðŸ“Š Checking GPU memory..."
nvidia-smi

# ë””ë ‰í† ë¦¬ ìƒì„±
echo "ðŸ“ Creating directories..."
mkdir -p models results logs

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export MASTER_PORT=29600
export WORLD_SIZE=8

echo "ðŸ”¥ Starting distributed training with 8 GPUs..."
echo "ðŸ“‹ Training Configuration:"
echo "   - Model: meta-llama/Llama-3.2-3B-Instruct"
echo "   - Epochs: 3"
echo "   - Batch size per GPU: 1"
echo "   - Gradient accumulation steps: 8"
echo "   - Effective batch size: 1 * 8 * 8 = 64"
echo "   - Learning rate: 5e-5"
echo "   - Mixed precision: Enabled"
echo "   - Auto sharding and merging: Enabled"

# DDPë¡œ main.py ì‹¤í–‰
torchrun --nproc_per_node=8 --master_port=$MASTER_PORT main.py \
    --pretrained_model_name "meta-llama/Llama-3.2-3B-Instruct" \
    --epochs 3 \
    --batch_size 1 \
    --gradient_accumulation_steps 8 \
    --use_amp \
    --lr 5e-5 \
    --save_path "models/llama3.2_3b_rgtnet.pth" \
    --results_file "results/llama3.2_3b_rgtnet_results.json" \
    --enable_benchmark \
    --benchmark_freq 1 \
    --dropout 0.1 \
    --bias_delta 1.0 \
    --weight_decay 0.01 \
    --warmup_ratio 0.1 \
    --download_datasets \
    --max_seq_len 8000 \
    --max_iters 8 \
    --train_only

# ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
END_TIME=$(date)
echo ""
echo "âœ… DDP Training completed!"
echo "ðŸ“… Training finished at: $END_TIME"
echo ""
echo "ðŸ“ Check the following directories for outputs:"
echo "   - Models: models/ (timestamped folders)"
echo "   - Results: results/ (timestamped folders)"
echo "   - Logs: logs/"

# ìµœì‹  ëª¨ë¸ í´ë” ì°¾ê¸°
LATEST_MODEL_DIR=$(ls -td models/llama3.2_3b_rgtnet_* 2>/dev/null | head -1)
if [ -n "$LATEST_MODEL_DIR" ]; then
    echo ""
    echo "ðŸŽ¯ Latest model saved in: $LATEST_MODEL_DIR"
    echo "ðŸ“„ Model file: $LATEST_MODEL_DIR/llama3.2_3b_rgtnet.pth"
fi